import torch
import librosa
from transformers import HubertModel, Wav2Vec2FeatureExtractor
import os
import glob
import numpy as np
from sklearn.neural_network import MLPClassifier
from datetime import datetime

# Define paths
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
INPUT_DIR = os.path.join(BASE_DIR, "audio_input")
OUTPUT_DIR = os.path.join(BASE_DIR, "audio_output")

def extract_hubert_embeddings(audio_file):
    print(f"Processing {os.path.basename(audio_file)}...")
    try:
        model_name = "facebook/hubert-base-ls960"
        feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)
        model = HubertModel.from_pretrained(model_name)
        
        # Load audio
        y, sr = librosa.load(audio_file, sr=16000)
        
        # Process audio
        inputs = feature_extractor(y, sampling_rate=sr, return_tensors="pt")
        
        with torch.no_grad():
            outputs = model(**inputs)
        
        # Get last hidden state and mean pool over time
        last_hidden_state = outputs.last_hidden_state
        embedding = torch.mean(last_hidden_state, dim=1).squeeze().numpy()
        return embedding
        
    except Exception as e:
        print(f"Error processing {audio_file}: {e}")
        return None

def generate_report(filename, prediction, probability):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    report_content = f"""# Cognitive Health Screening Report
    
**Date:** {timestamp}
**File:** {filename}
**Model:** HuBERT (Transformers)

## Results
- **Status:** {prediction}
- **Risk Probability:** {probability:.2%}

## Analysis
Speech patterns were analyzed using HuBERT embeddings to detect indicators of cognitive decline (pauses, articulation). The model suggests the sample is {prediction.lower()}.

---
*Generated by Synapxe Health screening prototype*
"""
    
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    output_filename = os.path.splitext(filename)[0] + "_cognitive_report.md"
    output_path = os.path.join(OUTPUT_DIR, output_filename)
    
    with open(output_path, "w") as f:
        f.write(report_content)
    
    print(f"Report generated: {output_path}")

def main():
    if not os.path.exists(INPUT_DIR):
        os.makedirs(INPUT_DIR)
        print(f"Created input directory: {INPUT_DIR}")
    
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"Created output directory: {OUTPUT_DIR}")

    # Find audio files
    audio_files = []
    for ext in ["*.wav", "*.mp3", "*.flac"]:
        audio_files.extend(glob.glob(os.path.join(INPUT_DIR, ext)))
    
    if not audio_files:
        print(f"No audio files found in {INPUT_DIR}")
        return

    # Train dummy classifier once
    print("Initializing classifier...")
    # Mock training data (768 dim embedding for HuBERT base)
    X_dummy = np.random.rand(50, 768)
    y_dummy = np.random.randint(0, 2, 50) # 0=Healthy, 1=risk
    clf = MLPClassifier(hidden_layer_sizes=(64,), max_iter=500)
    clf.fit(X_dummy, y_dummy)

    for audio_file in audio_files:
        features = extract_hubert_embeddings(audio_file)
        
        if features is not None:
            prediction_idx = clf.predict([features])[0]
            probability = clf.predict_proba([features])[0][1]
            
            label = "Cognitive Decline Risk" if prediction_idx == 1 else "Healthy"
            generate_report(os.path.basename(audio_file), label, probability)

if __name__ == "__main__":
    main()
